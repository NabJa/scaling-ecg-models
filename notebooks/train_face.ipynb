{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0550d687-e965-4f26-a32f-c8155fc5023a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from typing import Any, Callable, List, Optional, Sequence\n",
    "\n",
    "import torch\n",
    "from einops import rearrange\n",
    "from einops.layers.torch import Rearrange\n",
    "from torch import Tensor, nn\n",
    "from torch.nn import functional as F\n",
    "from torchvision.ops.stochastic_depth import StochasticDepth\n",
    "\n",
    "\n",
    "class CNBlockConfig1D:\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_channels: int,\n",
    "        out_channels: Optional[int],\n",
    "        num_layers: int,\n",
    "    ) -> None:\n",
    "        self.input_channels = input_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        s = self.__class__.__name__ + \"(\"\n",
    "        s += \"input_channels={input_channels}\"\n",
    "        s += \", out_channels={out_channels}\"\n",
    "        s += \", num_layers={num_layers}\"\n",
    "        s += \")\"\n",
    "        return s.format(**self.__dict__)\n",
    "\n",
    "\n",
    "class LayerNorm1D(nn.LayerNorm):\n",
    "    \"\"\"\n",
    "    Rearranges input from (N, C, S) to (N, S, C) to apply Layer Normalization over channels (C),\n",
    "    as nn.LayerNorm normalizes the last dimension. Returns input to original shape (N, C, S) after normalization.\n",
    "    \"\"\"\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        x = rearrange(x, \"N C S -> N S C\")\n",
    "        x = F.layer_norm(x, self.normalized_shape, self.weight, self.bias, self.eps)\n",
    "        x = rearrange(x, \"N S C -> N C S\")\n",
    "        return x\n",
    "\n",
    "\n",
    "class ResNetBlock1D(nn.Module):\n",
    "    \"\"\"\n",
    "    A ResNet residual block for 1D inputs with two Conv1d layers, BatchNorm, and ReLU activation.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dim, hidden_dim=None, downsample=False):\n",
    "        super().__init__()\n",
    "        hidden_dim = hidden_dim or dim\n",
    "        stride = 2 if downsample else 1\n",
    "\n",
    "        self.conv1 = nn.Conv1d(\n",
    "            dim, hidden_dim, kernel_size=3, stride=stride, padding=1, bias=False\n",
    "        )\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_dim)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv1d(hidden_dim, dim, kernel_size=3, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm1d(dim)\n",
    "\n",
    "        # Downsampling layer if needed\n",
    "        self.downsample = (\n",
    "            nn.Conv1d(dim, dim, kernel_size=1, stride=stride, bias=False)\n",
    "            if downsample\n",
    "            else None\n",
    "        )\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        # Apply downsampling if specified\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(identity)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class CNBlock1D(nn.Module):\n",
    "    \"\"\"\n",
    "    A ConvNeXt residual block for 1D inputs with depthwise convolution, LayerNorm, LayerScale,\n",
    "    GELU activation, inverted bottlneck, and stochastic depth regularization.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim,\n",
    "        layer_scale: float,\n",
    "        stochastic_depth_prob: float,\n",
    "        norm_layer: Optional[Callable[..., nn.Module]] = None,\n",
    "        bottleneck_inversion_factor: int = 4,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = partial(nn.LayerNorm, eps=1e-6)\n",
    "\n",
    "        inverted_bottleneck_dim = dim * bottleneck_inversion_factor\n",
    "\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv1d(dim, dim, kernel_size=7, padding=3, groups=dim, bias=True),\n",
    "            Rearrange(\"N S C -> N C S\"),\n",
    "            norm_layer(dim),\n",
    "            nn.Linear(\n",
    "                in_features=dim,\n",
    "                out_features=inverted_bottleneck_dim,\n",
    "                bias=True,\n",
    "            ),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(\n",
    "                in_features=inverted_bottleneck_dim,\n",
    "                out_features=dim,\n",
    "                bias=True,\n",
    "            ),\n",
    "            Rearrange(\"N C S -> N S C\"),\n",
    "        )\n",
    "        self.layer_scale = nn.Parameter(torch.ones(dim, 1) * layer_scale)\n",
    "        self.stochastic_depth = StochasticDepth(stochastic_depth_prob, \"row\")\n",
    "\n",
    "    def forward(self, input: Tensor) -> Tensor:\n",
    "        result = self.layer_scale * self.block(input)\n",
    "        result = self.stochastic_depth(result)\n",
    "        result += input\n",
    "        return result\n",
    "\n",
    "\n",
    "class ConvNeXt1D(nn.Module):\n",
    "    \"\"\"ConvNeXt1D model for ECG data classification.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        block_setting: List[CNBlockConfig1D],\n",
    "        stochastic_depth_prob: float = 0.0,\n",
    "        layer_scale: float = 1e-6,\n",
    "        channels=12,\n",
    "        num_classes: int = 5,\n",
    "        block: Optional[Callable[..., nn.Module]] = None,\n",
    "        norm_layer: Optional[Callable[..., nn.Module]] = None,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            block_setting: List of CNBlockConfig1D for each stage.\n",
    "            stochastic_depth_prob: Probability of dropping out a block. The probability is linearly increased.\n",
    "            layer_scale: Layer scale for LayerScale module.\n",
    "            channels: Number of input channels.\n",
    "            num_classes: Number of output classes.\n",
    "            block: Block module to use. Defaults to CNBlock1D.\n",
    "            norm_layer: Normalization layer to use. Defaults to LayerNorm1D.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        if not block_setting:\n",
    "            raise ValueError(\"The block_setting should not be empty\")\n",
    "        elif not (\n",
    "            isinstance(block_setting, Sequence)\n",
    "            and all([isinstance(s, CNBlockConfig1D) for s in block_setting])\n",
    "        ):\n",
    "            raise TypeError(\"The block_setting should be List[CNBlockConfig1D]\")\n",
    "\n",
    "        if block is None:\n",
    "            block = CNBlock1D\n",
    "\n",
    "        if norm_layer is None:\n",
    "            norm_layer = partial(LayerNorm1D, eps=1e-6)\n",
    "\n",
    "        layers: List[nn.Module] = []\n",
    "\n",
    "        # Stem\n",
    "        firstconv_output_channels = block_setting[0].input_channels\n",
    "        layers.append(\n",
    "            nn.Conv1d(\n",
    "                channels,\n",
    "                firstconv_output_channels,\n",
    "                kernel_size=4,\n",
    "                stride=4,\n",
    "                padding=0,\n",
    "                bias=True,\n",
    "            )\n",
    "        )\n",
    "\n",
    "        total_stage_blocks = sum(cnf.num_layers for cnf in block_setting)\n",
    "        stage_block_id = 0\n",
    "        for cnf in block_setting:\n",
    "            # Bottlenecks\n",
    "            stage: List[nn.Module] = []\n",
    "            for _ in range(cnf.num_layers):\n",
    "                # adjust stochastic depth probability based on the depth of the stage block\n",
    "                sd_prob = (\n",
    "                    stochastic_depth_prob * stage_block_id / (total_stage_blocks - 1.0)\n",
    "                )\n",
    "                stage.append(block(cnf.input_channels, layer_scale, sd_prob))\n",
    "                stage_block_id += 1\n",
    "            layers.append(nn.Sequential(*stage))\n",
    "            if cnf.out_channels is not None:\n",
    "                # Downsampling\n",
    "                layers.append(\n",
    "                    nn.Sequential(\n",
    "                        LayerNorm1D(cnf.input_channels, eps=1e-6),\n",
    "                        nn.Conv1d(\n",
    "                            cnf.input_channels,\n",
    "                            cnf.out_channels,\n",
    "                            kernel_size=2,\n",
    "                            stride=2,\n",
    "                        ),\n",
    "                    )\n",
    "                )\n",
    "\n",
    "        self.features = nn.Sequential(*layers)\n",
    "        self.avgpool = nn.AdaptiveAvgPool1d(1)\n",
    "\n",
    "        lastblock = block_setting[-1]\n",
    "        lastconv_output_channels = (\n",
    "            lastblock.out_channels\n",
    "            if lastblock.out_channels is not None\n",
    "            else lastblock.input_channels\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            norm_layer(lastconv_output_channels),\n",
    "            nn.Flatten(1),\n",
    "            nn.Linear(lastconv_output_channels, num_classes),\n",
    "        )\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, (nn.Conv1d, nn.Linear)):\n",
    "                nn.init.trunc_normal_(m.weight, std=0.02)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def convnext1d_tiny(**kwargs: Any) -> ConvNeXt1D:\n",
    "    return ConvNeXt1D(\n",
    "        [\n",
    "            CNBlockConfig1D(input_channels=24, out_channels=48, num_layers=3),\n",
    "            CNBlockConfig1D(input_channels=48, out_channels=96, num_layers=3),\n",
    "            CNBlockConfig1D(input_channels=96, out_channels=None, num_layers=3),\n",
    "        ],\n",
    "        **kwargs,\n",
    "    )\n",
    "\n",
    "\n",
    "def convnext1d_small(**kwargs: Any) -> ConvNeXt1D:\n",
    "    return ConvNeXt1D(\n",
    "        [\n",
    "            CNBlockConfig1D(input_channels=64, out_channels=96, num_layers=3),\n",
    "            CNBlockConfig1D(input_channels=96, out_channels=128, num_layers=3),\n",
    "            CNBlockConfig1D(input_channels=128, out_channels=256, num_layers=3),\n",
    "            CNBlockConfig1D(input_channels=256, out_channels=None, num_layers=3),\n",
    "        ],\n",
    "        **kwargs,\n",
    "    )\n",
    "\n",
    "\n",
    "def convnext1d_large(**kwargs: Any) -> ConvNeXt1D:\n",
    "    return ConvNeXt1D(\n",
    "        [\n",
    "            CNBlockConfig1D(input_channels=96, out_channels=128, num_layers=3),\n",
    "            CNBlockConfig1D(input_channels=128, out_channels=256, num_layers=3),\n",
    "            CNBlockConfig1D(input_channels=256, out_channels=512, num_layers=3),\n",
    "            CNBlockConfig1D(input_channels=512, out_channels=None, num_layers=3),\n",
    "        ],\n",
    "        **kwargs,\n",
    "    )\n",
    "\n",
    "\n",
    "def get_convnext(name: str, **kwargs: Any) -> ConvNeXt1D:\n",
    "    if name == \"tiny\":\n",
    "        return convnext1d_tiny(**kwargs)\n",
    "    elif name == \"small\":\n",
    "        return convnext1d_small(**kwargs)\n",
    "    elif name == \"large\":\n",
    "        return convnext1d_large(**kwargs)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown ConvNeXt model name: {name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c1865af-3ebd-4f99-9291-b12cc8163c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "def read_face_meta(path):\n",
    "    with open(path, mode=\"rb\") as file:\n",
    "        meta = pickle.load(file)\n",
    "    \n",
    "    for col in meta.columns:\n",
    "        if isinstance(meta.loc[0, col], list):\n",
    "            continue\n",
    "        \n",
    "        if len(meta[col].unique()) < 100:\n",
    "            meta[col] = meta[col].astype(\"category\")\n",
    "    \n",
    "    return meta\n",
    "\n",
    "\n",
    "def load_ecg(path, encoding, strip_index, n_channels=2):\n",
    "    assert encoding in [\"binary\", \"numpy\"]\n",
    "    \n",
    "    with h5py.File(path, \"r\") as file:\n",
    "        ecg_strip = file[\"ecg_strips\"][strip_index]\n",
    "        \n",
    "        if encoding == \"numpy\":\n",
    "            return np.moveaxis(ecg_strip.astype(np.float32), 0, -1)\n",
    "\n",
    "        binary_data = base64.b64decode(ecg_strip)\n",
    "        return np.frombuffer(binary_data, dtype=np.float32).reshape(n_channels, -1).copy()\n",
    "\n",
    "ROOT = Path(\"/sc-scratch/sc-scratch-gbm-radiomics/ecg/face\")\n",
    "FILES = ROOT / \"files\"\n",
    "LABEL_MAPPING = {0: \"SR\", 1: \"AFIB\", 2: \"OTHER\", 3: \"NOISE\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ecd3a828-3a81-481c-9dea-167f7be34adc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3235970/2943044690.py:13: DeprecationWarning: numpy.core.numeric is deprecated and has been renamed to numpy._core.numeric. The numpy._core namespace contains private NumPy internals and its use is discouraged, as NumPy internals can change without warning in any release. In practice, most real-world usage of numpy.core is to access functionality in the public NumPy API. If that is the case, use the public NumPy API. If not, you are using NumPy internals. If you would still like to access an internal attribute, use numpy._core.numeric._frombuffer.\n",
      "  meta = pickle.load(file)\n"
     ]
    }
   ],
   "source": [
    "meta = read_face_meta(ROOT / \"merged_meta.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f0cb592-e886-4c76-8419-e6781b1751dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_meta = meta.loc[meta.use_for_train == True].copy()\n",
    "# train_meta = train_meta[~train_meta.label.isna()]\n",
    "\n",
    "# valid_meta = meta.loc[meta.use_for_train == False].copy()\n",
    "# valid_meta = valid_meta[~valid_meta.label.isna()]\n",
    "\n",
    "# print(f\"Train examples: {len(train_meta):,}\\nValid examples: {len(valid_meta):,}\")\n",
    "# del train_meta, valid_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a75f47c0-7a14-4526-a2e5-8eaf719f0682",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import Compose\n",
    "from torch.nn.functional import pad\n",
    "import random\n",
    "\n",
    "def random_crop(x: torch.Tensor, seq_len: int) -> torch.Tensor:\n",
    "    \"\"\"Randomly crop a signal to a fixed length.\"\"\"\n",
    "    offset = 1 + x.size(-1) - seq_len\n",
    "    start = torch.randint(0, offset, (1,)).item()\n",
    "    return x[..., start : start + seq_len]\n",
    "\n",
    "\n",
    "class CropOrPad:\n",
    "    def __init__(self, seq_len=1_000, pad_mode=\"constant\"):\n",
    "        self.seq_len = seq_len\n",
    "        self.pad_mode = pad_mode\n",
    "\n",
    "    def __call__(self, x):\n",
    "        if x.size(-1) > self.seq_len:\n",
    "            return random_crop(x, self.seq_len)\n",
    "        if x.size(-1) < self.seq_len:\n",
    "            left_pad = (self.seq_len - x.size(-1)) // 2\n",
    "            right_pad = int(np.ceil((self.seq_len - x.size(-1)) / 2))\n",
    "            return pad(x, (left_pad, right_pad), mode=self.pad_mode)\n",
    "        return x\n",
    "\n",
    "class Dataset:\n",
    "    def __init__(self, root, meta, transform=None):\n",
    "        self.meta = meta\n",
    "        self.root = Path(root)\n",
    "        self.file_path = self.root / \"files\"\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.meta)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        sample = self.meta.iloc[index]\n",
    "\n",
    "        label = sample.label.item()\n",
    "\n",
    "        encoding = sample[\"hdf5-type\"]\n",
    "        strip_index = int(sample.strip_index)\n",
    "        path = self.file_path / f\"{sample.extracted_strips_filename}.hdf5\"\n",
    "        \n",
    "        ecg = load_ecg(path, encoding, strip_index)\n",
    "        ecg = torch.tensor(ecg)\n",
    "        \n",
    "        if self.transform:\n",
    "            ecg = self.transform(ecg)\n",
    "\n",
    "        return ecg, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8128b02c-7194-4aac-a2ea-b254aaa0c34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_nona = meta[~meta.label.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9fd3bbe9-f86a-462d-92d7-b562168c1ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_meta = meta_nona.iloc[np.arange(10)]\n",
    "valid_meta = meta_nona.iloc[np.arange(10, 20)]\n",
    "\n",
    "train_dataset = Dataset(ROOT, train_meta, transform=CropOrPad())\n",
    "valid_dataset = Dataset(ROOT, valid_meta, transform=CropOrPad())\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=4)\n",
    "valid_loader = DataLoader(valid_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "73ec2c50-8acb-4f40-83b3-bca33aaaac5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ecg, label = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "49e78a6e-d2f5-411d-9c0b-06fed9a2cb0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 2, 1000])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ecg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "133d8df0-e9f1-48b1-8218-cc067e032041",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 1])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5323765-fb63-4276-83e9-d132bb26b7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_params(model):\n",
    "    return sum([x.numel() for x in model.parameters() if x.requires_grad])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3fdf2a5a-31c7-43e5-97db-c183987120ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tiny 310,972\n",
      "small 2,417,252\n",
      "large 8,884,388\n"
     ]
    }
   ],
   "source": [
    "for m in [\"tiny\", \"small\", \"large\"]:\n",
    "    model = get_convnext(m, channels=2, num_classes=4)\n",
    "    params = count_params(model)\n",
    "    print(m, f\"{params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f9adb8-d683-493f-913b-b85bef85ecc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d6c4da-8cb2-410e-8cfa-db1c02996114",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-ecg]",
   "language": "python",
   "name": "conda-env-.conda-ecg-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
